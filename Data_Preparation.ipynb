{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21372d8e-914c-4cee-9581-292133e6d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36545d43-be41-4608-a06a-b2c9257a5b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH  = \"/home/achyuth/DL_Project/Predicting-Football-Injuries-using-LSTM/Cleaned_Dataset/dataset.csv\"\n",
    "OUTPUT_DIR = \"/home/achyuth/DL_Project/Predicting-Football-Injuries-using-LSTM/LSTM_Sequences/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb9c27d-29e0-473c-85a7-482616a7b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 15\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"injury_code\", \"age_at_injury\", \"height\", \"position_code\",\n",
    "    \"total_prior_injuries\", \"days_since_last_injury\",\n",
    "    \"same_site_reinjury\", \"days_since_same_site_injury\",\n",
    "]\n",
    "CONTINUOUS_COLS = [\n",
    "    \"age_at_injury\", \"height\",\n",
    "    \"days_since_last_injury\", \"days_since_same_site_injury\",\n",
    "]\n",
    "TARGET_COL = \"days_missed\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d4da4-4b9a-42b5-9911-4b758eaa8995",
   "metadata": {},
   "source": [
    "Applying log transform to 'Days Missed' since they have a right skew. Most injuries are minor and heal in a few days. But severe injuries take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636e4afa-37d1-4283-bbdd-4925dc6190d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[TARGET_COL] = np.log1p(df[TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488b29bd-7e57-4dba-b065-5bc9178d4f09",
   "metadata": {},
   "source": [
    "Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5fb864f-9a6c-4e00-b230-4e0eb4b4a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[CONTINUOUS_COLS] = scaler.fit_transform(df[CONTINUOUS_COLS])\n",
    "with open(f\"{OUTPUT_DIR}scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a967f6bb-9645-43c1-ba28-5e90582b07d8",
   "metadata": {},
   "source": [
    "Creating sequences for the LSTM. Grouping by player_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db8e1b6f-1538-4ec6-9e4f-af7dd962f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, targets = [], []\n",
    "for _, group in df.groupby(\"player_id\"):\n",
    "    features = group[FEATURE_COLS].values\n",
    "    labels   = group[TARGET_COL].values\n",
    "    for t in range(len(group)):\n",
    "        seq = features[: t + 1]\n",
    "        pad_len = MAX_SEQ_LEN - len(seq)\n",
    "        if pad_len > 0:\n",
    "            seq = np.vstack([np.zeros((pad_len, len(FEATURE_COLS))), seq])\n",
    "        else:\n",
    "            seq = seq[-MAX_SEQ_LEN:]\n",
    "        sequences.append(seq)\n",
    "        targets.append(labels[t])\n",
    "\n",
    "X = np.array(sequences, dtype=np.float32)\n",
    "y = np.array(targets,   dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35c022a-89f6-41f0-b298-2d452d6e189f",
   "metadata": {},
   "source": [
    "Creating training, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "476f9498-f4ff-46fa-bc3a-5543561181d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (96968, 15, 8), y: (96968,)\n",
      "Train: 77,574 | Val: 9,697 | Test: 9,697\n"
     ]
    }
   ],
   "source": [
    "n         = len(X)\n",
    "train_end = int(n * 0.80)\n",
    "val_end   = int(n * 0.90)\n",
    "\n",
    "X_train, y_train = X[:train_end],        y[:train_end]\n",
    "X_val,   y_val   = X[train_end:val_end], y[train_end:val_end]\n",
    "X_test,  y_test  = X[val_end:],          y[val_end:]\n",
    "\n",
    "np.save(f\"{OUTPUT_DIR}X_train.npy\", X_train)\n",
    "np.save(f\"{OUTPUT_DIR}y_train.npy\", y_train)\n",
    "np.save(f\"{OUTPUT_DIR}X_val.npy\",   X_val)\n",
    "np.save(f\"{OUTPUT_DIR}y_val.npy\",   y_val)\n",
    "np.save(f\"{OUTPUT_DIR}X_test.npy\",  X_test)\n",
    "np.save(f\"{OUTPUT_DIR}y_test.npy\",  y_test)\n",
    "\n",
    "print(f\"X: {X.shape}, y: {y.shape}\")\n",
    "print(f\"Train: {len(X_train):,} | Val: {len(X_val):,} | Test: {len(X_test):,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
